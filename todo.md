## Tarefas para a Fase 1: Análise de requisitos e estrutura do projeto

- [x] Criar a estrutura de diretórios do projeto.
- [x] Definir as bibliotecas Python necessárias para leitura de Excel, PDF e cálculo de similaridade: pandas, PyPDF2, fuzzywuzzy.
- [x] Esboçar a arquitetura geral do crawler: Módulo de leitura de Excel, Módulo de leitura de PDF, Módulo de comparação de texto com similaridade, Módulo de geração de relatório.

## Tarefas para a Fase 2: Desenvolvimento do crawler com funcionalidades de busca

- [x] Criar o arquivo `crawler.py`.
- [x] Implementar a função para ler o arquivo Excel e extrair os nomes dos clientes.
- [x] Implementar a função para ler o arquivo PDF e extrair o texto.




## Tarefas para a Fase 3: Implementação da lógica de similaridade e matching

- [x] Implementar a função para comparar os nomes dos clientes com o texto do PDF usando similaridade (fuzzywuzzy).
- [x] Implementar a lógica principal para orquestrar a leitura, comparação e geração de resultados.




## Tarefas para a Fase 4: Criação de arquivos de exemplo e testes

- [x] Criar um arquivo Excel de exemplo (`clientes.xlsx`) com uma lista de nomes de clientes.
- [x] Criar um arquivo PDF de exemplo (`documento.pdf`) com texto, incluindo alguns dos nomes de clientes do Excel.
- [x] Instalar as bibliotecas necessárias: `pandas`, `PyPDF2`, `fuzzywuzzy`, `python-Levenshtein`.
- [x] Executar o crawler com os arquivos de exemplo e verificar os resultados.




## Tarefas para a Fase 5: Documentação e entrega do projeto

- [x] Criar um arquivo `README.md` com a documentação do crawler, incluindo instruções de uso, requisitos e exemplos.
- [x] Gerar um PDF da documentação.
- [ ] Entregar os arquivos ao usuário.


