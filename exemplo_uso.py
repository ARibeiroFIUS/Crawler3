#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Exemplo de Uso do Crawler de Clientes em PDF
===========================================

Este script demonstra como usar a versÃ£o avanÃ§ada do crawler
para seus prÃ³prios arquivos Excel e PDF.
"""

from crawler_advanced import PDFClientCrawler

def exemplo_basico():
    """Exemplo bÃ¡sico de uso do crawler."""
    print("ðŸ” Executando exemplo bÃ¡sico...")
    
    # Criar instÃ¢ncia do crawler
    crawler = PDFClientCrawler(threshold=80, verbose=True)
    
    # Processar arquivos (substitua pelos seus arquivos)
    stats = crawler.process_files(
        excel_path="clientes.xlsx",      # Seu arquivo Excel
        pdf_path="documento.pdf",        # Seu arquivo PDF
        output_path="output/meus_resultados.xlsx"  # Arquivo de saÃ­da
    )
    
    if stats:
        print(f"\nâœ… Processamento concluÃ­do com sucesso!")
        print(f"Taxa de sucesso: {stats['success_rate']:.1f}%")
    else:
        print("\nâŒ Erro no processamento.")

def exemplo_personalizado():
    """Exemplo com configuraÃ§Ãµes personalizadas."""
    print("\nðŸ”§ Executando exemplo personalizado...")
    
    # Crawler com tolerÃ¢ncia maior e modo silencioso
    crawler = PDFClientCrawler(threshold=90, verbose=False)
    
    # Especificar coluna e aba diferentes do Excel
    stats = crawler.process_files(
        excel_path="clientes.xlsx",
        pdf_path="documento.pdf",
        output_path="output/resultados_personalizados.xlsx",
        excel_column=0,  # Primeira coluna (0-indexado)
        excel_sheet=0    # Primeira aba (0-indexado)
    )
    
    if stats:
        print(f"âœ… Processamento personalizado concluÃ­do!")
        print(f"Clientes encontrados: {stats['found_clients']}/{stats['total_clients']}")

def exemplo_multiplos_algoritmos():
    """Exemplo mostrando como os algoritmos de similaridade funcionam."""
    print("\nðŸ§  Demonstrando algoritmos de similaridade...")
    
    from fuzzywuzzy import fuzz
    
    # Exemplos de nomes com variaÃ§Ãµes
    cliente_original = "JoÃ£o da Silva"
    variaÃ§Ãµes = [
        "JoÃ£o Silva",          # Nome parcial
        "JOÃƒO DA SILVA",       # MaiÃºsculas
        "Joao da Silva",       # Sem acento
        "J. da Silva",         # Abreviado
        "JoÃ£o da Silva Jr.",   # Com sufixo
        "Silva, JoÃ£o da"       # Ordem invertida
    ]
    
    print(f"Cliente original: '{cliente_original}'")
    print("\nComparaÃ§Ãµes de similaridade:")
    
    for variacao in variaÃ§Ãµes:
        ratio = fuzz.ratio(cliente_original.lower(), variacao.lower())
        partial = fuzz.partial_ratio(cliente_original.lower(), variacao.lower())
        token = fuzz.token_sort_ratio(cliente_original.lower(), variacao.lower())
        
        print(f"  '{variacao}':")
        print(f"    Ratio: {ratio}% | Partial: {partial}% | Token: {token}%")
        print(f"    Seria encontrado com tolerÃ¢ncia 80%: {'Sim' if max(ratio, partial, token) >= 80 else 'NÃ£o'}")

if __name__ == "__main__":
    print("=" * 60)
    print("ðŸŽ¯ EXEMPLOS DE USO DO CRAWLER DE CLIENTES EM PDF")
    print("=" * 60)
    
    # Executar exemplos
    exemplo_basico()
    exemplo_personalizado()
    exemplo_multiplos_algoritmos()
    
    print("\n" + "=" * 60)
    print("ðŸ“š DICAS DE USO:")
    print("=" * 60)
    print("1. Coloque seu arquivo Excel e PDF na pasta do projeto")
    print("2. Use tolerÃ¢ncia 70-90% dependendo da qualidade dos dados")
    print("3. Verifique se a coluna correta estÃ¡ sendo lida do Excel")
    print("4. Os resultados sÃ£o salvos com metadados detalhados")
    print("5. Use 'python crawler_advanced.py --help' para ver todas as opÃ§Ãµes")
    print("=" * 60) 